---
layout:     post
title:      Concept of the Entropy 
subtitle:   信息 & 熵
date:       2020-06-12
author:     Xuan
header-img: img/post-bg-3.png
catalog: true
tags:
    - Entropy
---

# Basic definition about the entropy

Entropy: 事件（宏观态) 对观察者而言具体是哪种情况（微观态）的**不确定性** 叫做熵。

Information：消除观察者对事件的不确定性的事物 叫做信息。（只有能够消除某人对某件事情不确定性的事物才是信息）

以上两者， 熵和信息数量相等，意义相反。**获取信息意味着消除熵**。

能消除不确定性的信息有三种， 其本质为正确调整了每个可能情况的概率。

不能消除某人对某件事情不确定性的信息被称为 数据或噪音。噪音是信息获取的干扰，而数据是噪音与信息的混合，需要用知识将其分离。

# probably V.S. Entropy

概率：某事件（宏观态） 某个可能情况（微观态）的确定性， 概率的输入是微观态。

熵： 某人对某件事件到底是哪个状况的不确定性， 熵的输入是宏观态。

# Information 

像抛硬币这样只有两种等概率情况的事件时，测量的信息量就被定义为 1 bit。

![信息量如何定义_1](/img/post-ct-infor.png)
![信息量如何定义_2](/img/post-ct-entropy.png)

若事件的可能性并非等概率，要如何计算信息量？

分别测量事件每种可能情况的信息量后，乘以各自发生的概率在相加。


在例子中，不知道任何信息时，正确作出答案有可能为ABCD的选择题的熵，为2； （2=log2 4）ABCD有四种情况可选。

在被告知C选项有一半的概率正确后， 正确作答的熵降低为1.79， 计算如下：

![计算非等概率情况下熵的改变_1](/img/post-ct-compute.png)

概率为1/6事件的信息量，可以由其概率的倒数来进行替换。
![计算非等概率情况下熵的改变_2](/img/post-ct-transfer.png)

![计算非等概率情况下熵的改变_3](/img/post-ct-res.png)
 
# Reference

[信息熵是什么？](信息熵是什么？-YJango的回答-知乎
https://www.zhihu.com/question/22178202/answer/577936758)


